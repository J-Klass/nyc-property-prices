{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading useful extensions\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%load_ext nb_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sales_data_2015.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_data_cleaning(df):\n",
    "    \"\"\"\n",
    "    Cleaning the data set by deleting unused columns and filtering columns for unrealistic data\n",
    "    \"\"\"\n",
    "    # Deleting 0 values from the data set\n",
    "    df = df[(df.yr_built != 0) & (df.tot_sqft != 0) & (df.price != 0)]\n",
    "    # Deleting columns that are mostly NaN values and unused columns\n",
    "    df = df.copy().drop(\n",
    "        [\"easmnt\", \"apt\", \"Unnamed: 0\", \"usable\", \"zip\", \"block\", \"lot\"], axis=1\n",
    "    )\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates(df.columns, keep=\"last\")\n",
    "    # Drop nan values and reseting the index\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    # Remove observations that fall outside those caps\n",
    "    df = df[(df[\"price\"] > 100000) & (df[\"price\"] < 5000000)]\n",
    "    df = df[(df[\"tot_unit\"] > 0) & (df[\"tot_unit\"] != 2261)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data for Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df):\n",
    "    \"\"\"\n",
    "    One hot encoding all the categorical features\n",
    "    \"\"\"\n",
    "    df_categorical = df[[\"borough\", \"bldg_ctgy\", \"tax_cls_s\", \"tax_cls_p\"]]\n",
    "    # Changing the data type\n",
    "    df_categorical[\"borough\"] = df_categorical[\"borough\"].astype(object)\n",
    "    df_categorical[\"tax_cls_s\"] = df_categorical[\"tax_cls_s\"].astype(object)\n",
    "    # Convert categorical variables into dummy/indicator variables (i.e. one-hot encoding).\n",
    "    one_hot_encoded = pd.get_dummies(df_categorical)\n",
    "    return one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_nummerical_features(df):\n",
    "    \"\"\"\n",
    "    Scaling all the nummerical columns\n",
    "    \"\"\"\n",
    "    # Selecting all the nummerical features\n",
    "    df_nummerical = df[\n",
    "        [\n",
    "            \"res_unit\",\n",
    "            \"com_unit\",\n",
    "            \"tot_unit\",\n",
    "            \"land_sqft\",\n",
    "            \"tot_sqft\",\n",
    "            \"yr_built\",\n",
    "            \"price\",\n",
    "        ]\n",
    "    ]\n",
    "    # Transform the numeric features using log(x + 1)\n",
    "    skewed = df_nummerical[df_nummerical.columns].apply(\n",
    "        lambda x: skew(x.dropna().astype(float))\n",
    "    )\n",
    "    skewed = skewed[skewed > 0.75]\n",
    "    skewed = skewed.index\n",
    "    df_nummerical[skewed] = np.log1p(df_nummerical[skewed])\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_nummerical[df_nummerical.columns])\n",
    "    scaled = scaler.transform(df_nummerical[df_nummerical.columns])\n",
    "\n",
    "    for i, col in enumerate(df_nummerical.columns):\n",
    "        df_nummerical[col] = scaled[:, i]\n",
    "\n",
    "    return df_nummerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_data_cleaning(df):\n",
    "    \"\"\"\n",
    "    Cleaning data for regression models by removing unusable columns \n",
    "    Scaling nummerical columns\n",
    "    One hot encoding categorical columns\n",
    "    \"\"\"\n",
    "    # General data cleaning first\n",
    "    df = general_data_cleaning(df)\n",
    "    # Extracting Sale_id\n",
    "    df_sale = df[[\"Sale_id\"]]\n",
    "    # Removing unused columns\n",
    "    df = df.copy().drop(\n",
    "        [\n",
    "            \"bbl_id\",\n",
    "            \"address\",\n",
    "            \"sale_date\",\n",
    "            \"long\",\n",
    "            \"lat\",\n",
    "            \"year\",\n",
    "            \"bldg_cls_p\",\n",
    "            \"bldg_cls_s\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    # Run scaling and one hot encoding\n",
    "    df = pd.concat([scaling_nummerical_features(df), one_hot_encoding(df)], axis=1)\n",
    "    # Adding Sale_id back to the data frame\n",
    "    df = pd.concat([df_sale, df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = regression_data_cleaning(df)\n",
    "df_eda = general_data_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.to_csv(\"df_reg.csv\")\n",
    "df_eda.to_csv(\"df_eda.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
