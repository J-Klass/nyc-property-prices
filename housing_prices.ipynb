{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the New York City Property Prices Dataset <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading useful extensions\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%load_ext nb_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sales_data_2015.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has 26 dimensions, which are listed below. Some of the attribute names are quite ambiguous, such are the codes for tax and building classes. For more information you can have a look at\n",
    "https://www1.nyc.gov/assets/finance/downloads/pdf/07pdf/glossary_rsf071607.pdf\n",
    "and\n",
    "https://www1.nyc.gov/assets/finance/jump/hlpbldgcode.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NaN values\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.duplicated(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = general_data_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_eda[\"price\"])\n",
    "# sns.distplot(df_eda[\"price\"]).get_figure().savefig(\"output.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = np.log(df_eda[\"price\"])\n",
    "print(sales.skew())\n",
    "sns.distplot(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_data_cleaning(df):\n",
    "    \"\"\"\n",
    "    Cleaning the data set by deleting unused columns and filtering columns for unrealistic data\n",
    "    \"\"\"\n",
    "    # Deleting 0 values from the data set\n",
    "    df = df[(df.yr_built != 0) & (df.tot_sqft != 0) & (df.price != 0)]\n",
    "    # Deleting columns that are mostly NaN values and unused columns\n",
    "    df = df.copy().drop([\"easmnt\", \"apt\", \"Unnamed: 0\", \"usable\"], axis=1)\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates(df.columns, keep=\"last\")\n",
    "    # Drop nan values and reseting the index\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index(drop=True)\n",
    "    # Remove observations that fall outside those caps\n",
    "    df = df[(df[\"price\"] > 100000) & (df[\"price\"] < 5000000)]\n",
    "    df = df[(df[\"tot_unit\"] > 0) & (df[\"tot_unit\"] != 2261)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_nummerical_features(df):\n",
    "    \"\"\"\n",
    "    Scaling all the nummerical columns\n",
    "    \"\"\"\n",
    "    # Selecting all the nummerical features\n",
    "    df_nummerical = df[\n",
    "        [\n",
    "            \"block\",\n",
    "            \"lot\",\n",
    "            \"zip\",\n",
    "            \"res_unit\",\n",
    "            \"com_unit\",\n",
    "            \"tot_unit\",\n",
    "            \"land_sqft\",\n",
    "            \"tot_sqft\",\n",
    "            \"yr_built\",\n",
    "            \"price\",\n",
    "        ]\n",
    "    ]\n",
    "    # Transform the numeric features using log(x + 1)\n",
    "    skewed = df_nummerical[df_nummerical.columns].apply(\n",
    "        lambda x: skew(x.dropna().astype(float))\n",
    "    )\n",
    "    skewed = skewed[skewed > 0.75]\n",
    "    skewed = skewed.index\n",
    "    df_nummerical[skewed] = np.log1p(df_nummerical[skewed])\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_nummerical[df_nummerical.columns])\n",
    "    scaled = scaler.transform(df_nummerical[df_nummerical.columns])\n",
    "\n",
    "    for i, col in enumerate(df_nummerical.columns):\n",
    "        df_nummerical[col] = scaled[:, i]\n",
    "\n",
    "    return df_nummerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df):\n",
    "    \"\"\"\n",
    "    One hot encoding all the categorical features\n",
    "    \"\"\"\n",
    "    df_categorical = df[[\"borough\", \"bldg_ctgy\", \"tax_cls_s\", \"tax_cls_p\"]]\n",
    "    # Changing the data type\n",
    "    df_categorical[\"borough\"] = df_categorical[\"borough\"].astype(object)\n",
    "    df_categorical[\"tax_cls_s\"] = df_categorical[\"tax_cls_s\"].astype(object)\n",
    "    # Convert categorical variables into dummy/indicator variables (i.e. one-hot encoding).\n",
    "    one_hot_encoded = pd.get_dummies(df_categorical)\n",
    "    return one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_data_cleaning(df):\n",
    "    \"\"\"\n",
    "    Cleaning data for regression models by removing unusable columns \n",
    "    Scaling nummerical columns\n",
    "    One hot encoding categorical columns\n",
    "    \"\"\"\n",
    "    # General data cleaning first\n",
    "    df = general_data_cleaning(df)\n",
    "    # Extracting Sale_id\n",
    "    df_sale = df[[\"Sale_id\"]]\n",
    "    # Removing unused columns\n",
    "    df = df.copy().drop(\n",
    "        [\n",
    "            \"bbl_id\",\n",
    "            \"address\",\n",
    "            \"sale_date\",\n",
    "            \"long\",\n",
    "            \"lat\",\n",
    "            \"year\",\n",
    "            \"bldg_cls_p\",\n",
    "            \"bldg_cls_s\",\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    # Run scaling and one hot encoding\n",
    "    df = pd.concat([scaling_nummerical_features(df), one_hot_encoding(df)], axis=1)\n",
    "    # Adding Sale_id back to the data frame\n",
    "    df = pd.concat([df_sale, df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = regression_data_cleaning(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Sale_id\n",
    "del df_reg[\"Sale_id\"]\n",
    "# Calculating correlations\n",
    "corr = df_reg.corr()\n",
    "corr.style.background_gradient(cmap=\"coolwarm\", axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_reg.pop(\"price\")\n",
    "X = df_reg\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=40\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Definition iof the RMSE (Root Mean Square Error)\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Performing a simple linear regression\n",
    "    \"\"\"\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    # Return metrics\n",
    "    return {\n",
    "        \"name\": \"Linear Regression (Baseline)\",\n",
    "        \"R squared\": linreg.score(X_test, y_test),\n",
    "        \"R squared training\": linreg.score(X_train, y_train),\n",
    "        \"RMSE\": rmse(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the regression\n",
    "# linear_regression(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(X_train, y_train, X_test, y_test, plot):\n",
    "    \"\"\"\n",
    "    Perfomring a lasso regression with built in CV and plotting the feature importance\n",
    "    \"\"\"\n",
    "    # Fit the ridge regression\n",
    "    reg = LassoCV()\n",
    "    reg.fit(X_train, y_train)\n",
    "    print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "    print(\"Best score using built-in LassoCV: %f\" % reg.score(X_train, y_train))\n",
    "    coef = pd.Series(reg.coef_, index=X_train.columns)\n",
    "    print(\n",
    "        \"Lasso picked \"\n",
    "        + str(sum(coef != 0))\n",
    "        + \" variables and eliminated the other \"\n",
    "        + str(sum(coef == 0))\n",
    "        + \" variables\"\n",
    "    )\n",
    "    # Extract the feature importance\n",
    "    imp_coef = coef.sort_values()\n",
    "    # Plot the feature importance\n",
    "    if plot:\n",
    "        plt.rcParams[\"figure.figsize\"] = (8.0, 10.0)\n",
    "        imp_coef.plot(kind=\"barh\")\n",
    "        plt.title(\"Feature importance using Lasso Model\")\n",
    "    # Using the test data to calculate a score\n",
    "    y_pred = reg.predict(X_test)\n",
    "    # Return metrics\n",
    "    return {\n",
    "        \"name\": \"Lasso Regression\",\n",
    "        \"R squared\": reg.score(X_test, y_test),\n",
    "        \"RMSE\": rmse(y_test, y_pred),\n",
    "        \"R squared training\": reg.score(X_train, y_train),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the regression\n",
    "# lasso_regression(X_train, y_train, X_test, y_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X_train, y_train, X_test, y_test, plot):\n",
    "    \"\"\"\n",
    "    Perfomring a ridge regression with built in CV and plotting the feature importance\n",
    "    \"\"\"\n",
    "    # Fit the ridge regression\n",
    "    reg = RidgeCV()\n",
    "    reg.fit(X_train, y_train)\n",
    "    print(\"Best alpha using built-in RidgeCV: %f\" % reg.alpha_)\n",
    "    print(\"Best score using built-in RidgeCV: %f\" % reg.score(X_train, y_train))\n",
    "    coef = pd.Series(reg.coef_, index=X_train.columns)\n",
    "    print(\n",
    "        \"Ridge picked \"\n",
    "        + str(sum(coef != 0))\n",
    "        + \" variables and eliminated the other \"\n",
    "        + str(sum(coef == 0))\n",
    "        + \" variables\"\n",
    "    )\n",
    "    # Extract the feature importance\n",
    "    imp_coef = coef.sort_values()\n",
    "    # Plot the feature importance\n",
    "    if plot:\n",
    "        plt.rcParams[\"figure.figsize\"] = (8.0, 10.0)\n",
    "        imp_coef.plot(kind=\"barh\")\n",
    "        plt.title(\"Feature importance using Ridge Model\")\n",
    "    # Using the test data to calculate a score\n",
    "    y_pred = reg.predict(X_test)\n",
    "    # Return metrics\n",
    "    return {\n",
    "        \"name\": \"Ridge Regression\",\n",
    "        \"R squared\": reg.score(X_test, y_test),\n",
    "        \"R squared training\": reg.score(X_train, y_train),\n",
    "        \"RMSE\": rmse(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the regression\n",
    "# ridge_regression(X_train, y_train, X_test, y_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regression(X_train, y_train, X_test, y_test, plot):\n",
    "    \"\"\"\n",
    "    Random Forest Regression using grid search for the parameter tuning \n",
    "    and plotting the feature importances\n",
    "    \"\"\"\n",
    "    # Random forest regressor\n",
    "    rf = RandomForestRegressor(random_state=0)\n",
    "    # Grid search for parameter tuning\n",
    "    params = {\n",
    "        \"n_estimators\": [10, 20, 30],\n",
    "        \"max_features\": [\"auto\", \"log2\", \"sqrt\"],\n",
    "        \"bootstrap\": [True, False],\n",
    "    }\n",
    "    reg = GridSearchCV(rf, params, cv=5)\n",
    "    reg.fit(X_train, y_train)\n",
    "    estimator = reg.best_estimator_\n",
    "    # Using the test data to calculate a score\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(\"Score on test data: \", estimator.score(X_test, y_test))\n",
    "    print(\"Root Mean Square Error: \", rmse(y_test, y_pred))\n",
    "    # Plotting the feature importances\n",
    "    if plot:\n",
    "        feat_importances = pd.Series(\n",
    "            estimator.feature_importances_, index=X_train.columns\n",
    "        ).sort_values(ascending=True)\n",
    "        feat_importances.plot(kind=\"barh\")\n",
    "    return {\n",
    "        \"name\": \"Random Forest Regression\",\n",
    "        \"R squared\": estimator.score(X_test, y_test),\n",
    "        \"R squared training\": estimator.score(X_train, y_train),\n",
    "        \"RMSE\": rmse(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the regression\n",
    "# random_forest_regression(X_train, y_train, X_test, y_test, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(\n",
    "    [\n",
    "        linear_regression(X_train, y_train, X_test, y_test),\n",
    "        lasso_regression(X_train, y_train, X_test, y_test, False),\n",
    "        ridge_regression(X_train, y_train, X_test, y_test, False),\n",
    "        random_forest_regression(X_train, y_train, X_test, y_test, False),\n",
    "    ]\n",
    ")\n",
    "summary.sort_values(\"R squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Visual Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vis = pd.read_csv(\"sales_data_2015_DF-inception-conv.csv\")\n",
    "# Delete unused columns\n",
    "df_vis = df_vis.copy().drop([\"bbl_id\", \"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vis_reg = pd.merge(regression_data_cleaning(df), df_vis, on=\"Sale_id\", how=\"inner\")\n",
    "# Drop Sale_id\n",
    "del df_vis_reg[\"Sale_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerunning the Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vis = df_vis_reg.pop(\"price\")\n",
    "X_vis = df_vis_reg\n",
    "X_train_vis, X_test_vis, y_train_vis, y_test_vis = train_test_split(\n",
    "    X_vis, y_vis, test_size=0.20, random_state=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(\n",
    "    [\n",
    "        linear_regression(X_train_vis, y_train_vis, X_test_vis, y_test_vis),\n",
    "        lasso_regression(X_train_vis, y_train_vis, X_test_vis, y_test_vis, False),\n",
    "        ridge_regression(X_train_vis, y_train_vis, X_test_vis, y_test_vis, False),\n",
    "        random_forest_regression(\n",
    "            X_train_vis, y_train_vis, X_test_vis, y_test_vis, False\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "summary.sort_values(\"R squared\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
